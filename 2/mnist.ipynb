{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        国家  2019国际排名  2018世界杯排名  2015亚洲杯排名  聚类结果\n",
      "0       中国        73         40          7     2\n",
      "1       日本        60         15          5     1\n",
      "2       韩国        61         19          2     1\n",
      "3       伊朗        34         18          6     1\n",
      "4       沙特        67         26         10     1\n",
      "5      伊拉克        91         40          4     2\n",
      "6      卡塔尔       101         40         13     0\n",
      "7      阿联酋        81         40          6     2\n",
      "8   乌兹别克斯坦        88         40          8     2\n",
      "9       泰国       122         40         17     0\n",
      "10      越南       102         50         17     0\n",
      "11      阿曼        87         50         12     0\n",
      "12      朝鲜       110         50         14     0\n",
      "13      印尼       164         50         17     0\n",
      "14      澳洲        40         30          1     1\n",
      "15     叙利亚        76         40         17     0\n",
      "16      约旦       118         50          9     0\n",
      "17     科威特       160         50         15     0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 数据加载\n",
    "\n",
    "data = pd.read_csv('team_cluster_data.csv', encoding='gbk')\n",
    "\n",
    "train_x = data[[\"2019国际排名\",\"2018世界杯排名\",\"2015亚洲杯排名\"]]\n",
    "\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "\n",
    "# 规范化到 [0,1] 空间\n",
    "\n",
    "min_max_scaler=preprocessing.MinMaxScaler()\n",
    "\n",
    "train_x=min_max_scaler.fit_transform(train_x)\n",
    "\n",
    "#print(train_x)\n",
    "\n",
    "# kmeans 算法\n",
    "\n",
    "kmeans.fit(train_x)\n",
    "\n",
    "predict_y = kmeans.predict(train_x)\n",
    "\n",
    "# 合并聚类结果，插入到原数据中\n",
    "\n",
    "result = pd.concat((data,pd.DataFrame(predict_y)),axis=1)\n",
    "\n",
    "result.rename({0:u'聚类结果'},axis=1,inplace=True)\n",
    "\n",
    "print(result)\n",
    "\n",
    "# 将结果导出到CSV文件中\n",
    "\n",
    "#result.to_csv(\"team_cluster_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (1797, 64)\n",
      "[[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
      " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
      " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
      " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
      " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
      " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
      " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
      " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n",
      "0\n",
      "16.0\n",
      "40971\n",
      "86208\n",
      "LR准确率: 0.9600\n",
      "CART决策树准确率: 0.8489\n",
      "LDA准确率: 0.9378\n",
      "朴素贝叶斯准确率: 0.8311\n",
      "SVM准确率: 0.9867\n",
      "KNN准确率: 0.9756\n",
      "AdaBoost准确率: 0.9644\n"
     ]
    }
   ],
   "source": [
    "# 使用多种分类器进行MNIST手写数字分类\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "from sklearn import svm #SVM\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression #逻辑回归\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier #决策树\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB #高斯朴素贝叶斯 GaussianNB/MultinomialNB/BernoulliNB\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier #KNN\n",
    "\n",
    "from sklearn.ensemble import  AdaBoostClassifier #AdaBoost\n",
    "\n",
    "# from xgboost import XGBClassifier #XGBoost\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis  \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 加载数据\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "data = digits.data\n",
    "\n",
    "# 数据探索\n",
    "\n",
    "print('data shape:', data.shape)\n",
    "\n",
    "# 查看第一幅图像\n",
    "\n",
    "print(digits.images[0])\n",
    "\n",
    "# 第一幅图像代表的数字含义\n",
    "\n",
    "print(digits.target[0])\n",
    "\n",
    "# 将第一幅图像显示出来\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "plt.gray()\n",
    "\n",
    "plt.imshow(digits.images[0])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# 分割数据，将25%的数据作为测试集，其余作为训练集\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(data, digits.target, test_size=0.25, random_state=33)\n",
    "\n",
    "print(train_x.max())\n",
    "\n",
    "print((train_x>1).sum())\n",
    "\n",
    "print(train_x.shape[0]*train_x.shape[1])\n",
    "\n",
    "# 采用Z-Score规范化\n",
    "\n",
    "ss = preprocessing.StandardScaler()\n",
    "\n",
    "train_ss_x = ss.fit_transform(train_x)\n",
    "\n",
    "test_ss_x = ss.transform(test_x)\n",
    "\n",
    "\n",
    "\n",
    "# 创建LR分类器\n",
    "\n",
    "lr = LogisticRegression(solver='liblinear', multi_class='auto') #数据集比较小，使用liblinear，数据集大使用 sag或者saga\n",
    "\n",
    "lr.fit(train_ss_x, train_y)\n",
    "\n",
    "predict_y=lr.predict(test_ss_x)\n",
    "\n",
    "print('LR准确率: %0.4lf' % accuracy_score(predict_y, test_y))\n",
    "\n",
    "\n",
    "\n",
    "# 创建线性 CART决策树分类器\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "model.fit(train_ss_x,train_y)\n",
    "\n",
    "predict_y=model.predict(test_ss_x)\n",
    "\n",
    "print('CART决策树准确率: %0.4lf' %accuracy_score(predict_y,test_y))\n",
    "\n",
    "\n",
    "\n",
    "# 创建LDA分类器\n",
    "\n",
    "model = LinearDiscriminantAnalysis(n_components=2)\n",
    "\n",
    "model.fit(train_ss_x,train_y)\n",
    "\n",
    "predict_y=model.predict(test_ss_x)\n",
    "\n",
    "print('LDA准确率: %0.4lf' %accuracy_score(predict_y,test_y))\n",
    "\n",
    "\n",
    "\n",
    "# 创建贝叶斯分类器\n",
    "\n",
    "model = GaussianNB()\n",
    "\n",
    "model.fit(train_x,train_y)\n",
    "\n",
    "predict_y=model.predict(test_x)\n",
    "\n",
    "print('朴素贝叶斯准确率: %0.4lf' %accuracy_score(predict_y,test_y))\n",
    "\n",
    "\n",
    "\n",
    "# 创建SVM分类器\n",
    "\n",
    "model = svm.SVC(kernel='rbf', C=1.0, gamma='auto')\n",
    "\n",
    "model.fit(train_ss_x,train_y)\n",
    "\n",
    "predict_y=model.predict(test_ss_x)\n",
    "\n",
    "print('SVM准确率: %0.4lf' %accuracy_score(predict_y,test_y))\n",
    "\n",
    "\n",
    "\n",
    "# 创建KNN分类器\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "model.fit(train_ss_x,train_y)\n",
    "\n",
    "predict_y=model.predict(test_ss_x)\n",
    "\n",
    "print('KNN准确率: %0.4lf' %accuracy_score(predict_y,test_y))\n",
    "\n",
    "\n",
    "\n",
    "# 创建AdaBoost分类器\n",
    "\n",
    "# 弱分类器\n",
    "\n",
    "dt_stump = DecisionTreeClassifier(max_depth=5,min_samples_leaf=1)\n",
    "\n",
    "dt_stump.fit(train_ss_x, train_y)\n",
    "\n",
    "#dt_stump_err = 1.0-dt_stump.score(test_x, test_y)\n",
    "\n",
    "# 设置AdaBoost迭代次数\n",
    "\n",
    "n_estimators=500\n",
    "\n",
    "model = AdaBoostClassifier(base_estimator=dt_stump,n_estimators=n_estimators)\n",
    "\n",
    "model.fit(train_ss_x,train_y)\n",
    "\n",
    "predict_y=model.predict(test_ss_x)\n",
    "\n",
    "print('AdaBoost准确率: %0.4lf' %accuracy_score(predict_y,test_y))\n",
    "\n",
    "\n",
    "\n",
    "# 创建XGBoost分类器\n",
    "\n",
    "# model = XGBClassifier()\n",
    "\n",
    "# model.fit(train_ss_x,train_y)\n",
    "\n",
    "# predict_y=model.predict(test_ss_x)\n",
    "\n",
    "# print('XGBoost准确率: %0.4lf' %accuracy_score(predict_y,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 ... 8 9 8]\n",
      "Warning: xgboost.XGBClassifier is not available and will not be used by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=120.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.9792069392812888\n",
      "Generation 2 - Current best internal CV score: 0.9792069392812888\n",
      "Generation 3 - Current best internal CV score: 0.9792124466473909\n",
      "Generation 4 - Current best internal CV score: 0.9792124466473909\n",
      "Generation 5 - Current best internal CV score: 0.9792124466473909\n",
      "\n",
      "Best pipeline: ExtraTreesClassifier(CombineDFs(Nystroem(input_matrix, gamma=0.15000000000000002, kernel=chi2, n_components=4), input_matrix), bootstrap=False, criterion=entropy, max_features=0.3, min_samples_leaf=1, min_samples_split=14, n_estimators=100)\n",
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# 使用TPOT自动机器学习工具对MNIST进行分类\n",
    "\n",
    "from tpot import TPOTClassifier\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# 加载数据\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "data = digits.data\n",
    "\n",
    "print(digits.target)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data.astype(np.float64),\n",
    "\n",
    "    digits.target.astype(np.float64), train_size=0.75, test_size=0.25)\n",
    "\n",
    "\n",
    "\n",
    "tpot = TPOTClassifier(generations=5, population_size=20, verbosity=2)\n",
    "\n",
    "tpot.fit(X_train, y_train)\n",
    "\n",
    "print(tpot.score(X_test, y_test))\n",
    "\n",
    "tpot.export('tpot_mnist_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "查看数据信息：列名、非空个数、类型等\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n",
      "------------------------------\n",
      "查看数据摘要\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "------------------------------\n",
      "查看离散数据分布\n",
      "                          Name   Sex Ticket    Cabin Embarked\n",
      "count                      891   891    891      204      889\n",
      "unique                     891     2    681      147        3\n",
      "top     Gheorgheff, Mr. Stanio  male   1601  B96 B98        S\n",
      "freq                         1   577      7        4      644\n",
      "------------------------------\n",
      "查看前5条数据\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "------------------------------\n",
      "查看后5条数据\n",
      "     PassengerId  Survived  Pclass                                      Name  \\\n",
      "886          887         0       2                     Montvila, Rev. Juozas   \n",
      "887          888         1       1              Graham, Miss. Margaret Edith   \n",
      "888          889         0       3  Johnston, Miss. Catherine Helen \"Carrie\"   \n",
      "889          890         1       1                     Behr, Mr. Karl Howell   \n",
      "890          891         0       3                       Dooley, Mr. Patrick   \n",
      "\n",
      "        Sex   Age  SibSp  Parch      Ticket   Fare Cabin Embarked  \n",
      "886    male  27.0      0      0      211536  13.00   NaN        S  \n",
      "887  female  19.0      0      0      112053  30.00   B42        S  \n",
      "888  female   NaN      1      2  W./C. 6607  23.45   NaN        S  \n",
      "889    male  26.0      0      0      111369  30.00  C148        C  \n",
      "890    male  32.0      0      0      370376   7.75   NaN        Q  \n",
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: Embarked, dtype: int64\n",
      "特征值\n",
      "     Pclass     Sex        Age  SibSp  Parch     Fare Embarked\n",
      "0         3    male  22.000000      1      0   7.2500        S\n",
      "1         1  female  38.000000      1      0  71.2833        C\n",
      "2         3  female  26.000000      0      0   7.9250        S\n",
      "3         1  female  35.000000      1      0  53.1000        S\n",
      "4         3    male  35.000000      0      0   8.0500        S\n",
      "..      ...     ...        ...    ...    ...      ...      ...\n",
      "886       2    male  27.000000      0      0  13.0000        S\n",
      "887       1  female  19.000000      0      0  30.0000        S\n",
      "888       3  female  29.699118      1      2  23.4500        S\n",
      "889       1    male  26.000000      0      0  30.0000        C\n",
      "890       3    male  32.000000      0      0   7.7500        Q\n",
      "\n",
      "[891 rows x 7 columns]\n",
      "['Age', 'Embarked=C', 'Embarked=Q', 'Embarked=S', 'Fare', 'Parch', 'Pclass', 'Sex=female', 'Sex=male', 'SibSp']\n",
      "score准确率为 0.9820\n",
      "cross_val_score准确率为 0.7834\n"
     ]
    }
   ],
   "source": [
    "# titanic 数据清洗\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "\n",
    "\n",
    "# 数据加载\n",
    "\n",
    "train_data = pd.read_csv('./train.csv')\n",
    "\n",
    "test_data = pd.read_csv('./test.csv')\n",
    "\n",
    "# 数据探索\n",
    "\n",
    "# 查看train_data信息\n",
    "\n",
    "#pd.set_option('display.max_columns', None) #显示所有列\n",
    "\n",
    "print('查看数据信息：列名、非空个数、类型等')\n",
    "\n",
    "print(train_data.info())\n",
    "\n",
    "print('-'*30)\n",
    "\n",
    "print('查看数据摘要')\n",
    "\n",
    "print(train_data.describe())\n",
    "\n",
    "print('-'*30)\n",
    "\n",
    "print('查看离散数据分布')\n",
    "\n",
    "print(train_data.describe(include=['O']))\n",
    "\n",
    "print('-'*30)\n",
    "\n",
    "print('查看前5条数据')\n",
    "\n",
    "print(train_data.head())\n",
    "\n",
    "print('-'*30)\n",
    "\n",
    "print('查看后5条数据')\n",
    "\n",
    "print(train_data.tail())\n",
    "\n",
    "\n",
    "\n",
    "# 使用平均年龄来填充年龄中的nan值\n",
    "\n",
    "train_data['Age'].fillna(train_data['Age'].mean(), inplace=True)\n",
    "\n",
    "test_data['Age'].fillna(test_data['Age'].mean(),inplace=True)\n",
    "\n",
    "# 使用票价的均值填充票价中的nan值\n",
    "\n",
    "train_data['Fare'].fillna(train_data['Fare'].mean(), inplace=True)\n",
    "\n",
    "test_data['Fare'].fillna(test_data['Fare'].mean(),inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "print(train_data['Embarked'].value_counts())\n",
    "\n",
    "# 使用登录最多的港口来填充登录港口的nan值\n",
    "\n",
    "train_data['Embarked'].fillna('S', inplace=True)\n",
    "\n",
    "test_data['Embarked'].fillna('S',inplace=True)\n",
    "\n",
    "# 特征选择\n",
    "\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "\n",
    "train_features = train_data[features]\n",
    "\n",
    "train_labels = train_data['Survived']\n",
    "\n",
    "test_features = test_data[features]\n",
    "\n",
    "print('特征值')\n",
    "\n",
    "print(train_features)\n",
    "\n",
    "\n",
    "\n",
    "dvec=DictVectorizer(sparse=False)\n",
    "\n",
    "train_features=dvec.fit_transform(train_features.to_dict(orient='record'))\n",
    "\n",
    "print(dvec.feature_names_)\n",
    "\n",
    "# 构造ID3决策树\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion='entropy')\n",
    "\n",
    "# 决策树训练\n",
    "\n",
    "clf.fit(train_features, train_labels)\n",
    "\n",
    "\n",
    "\n",
    "test_features=dvec.transform(test_features.to_dict(orient='record'))\n",
    "\n",
    "# 决策树预测\n",
    "\n",
    "pred_labels = clf.predict(test_features)\n",
    "\n",
    "\n",
    "\n",
    "# 得到决策树准确率(基于训练集)\n",
    "\n",
    "acc_decision_tree = round(clf.score(train_features, train_labels), 6)\n",
    "\n",
    "print(u'score准确率为 %.4lf' % acc_decision_tree)\n",
    "\n",
    "\n",
    "\n",
    "# 使用K折交叉验证 统计决策树准确率\n",
    "\n",
    "print(u'cross_val_score准确率为 %.4lf' % np.mean(cross_val_score(clf, train_features, train_labels, cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "显示前5条数据\n",
      "      UserID                        Game    Action  Hours  Not Needed\n",
      "0  151603712  The Elder Scrolls V Skyrim  purchase    1.0           0\n",
      "1  151603712  The Elder Scrolls V Skyrim      play  273.0           0\n",
      "2  151603712                   Fallout 4  purchase    1.0           0\n",
      "3  151603712                   Fallout 4      play   87.0           0\n",
      "4  151603712                       Spore  purchase    1.0           0\n",
      "显示数据大小\n",
      "(200000, 5)\n",
      "0           0.0\n",
      "1         273.0\n",
      "2           0.0\n",
      "3          87.0\n",
      "4           0.0\n",
      "          ...  \n",
      "199995      1.5\n",
      "199996      0.0\n",
      "199997      1.5\n",
      "199998      0.0\n",
      "199999      1.4\n",
      "Name: Hours_Played, Length: 200000, dtype: float32\n",
      "增加了Hours_Played字段后，数据大小\n",
      "(200000, 6)\n",
      "删除重复项后的数据集：\n",
      "           UserID                          Game  Hours_Played\n",
      "65430        5250                   Alien Swarm           4.9\n",
      "65424        5250               Cities Skylines         144.0\n",
      "65435        5250                Counter-Strike           0.0\n",
      "65436        5250         Counter-Strike Source           0.0\n",
      "65437        5250                 Day of Defeat           0.0\n",
      "...           ...                           ...           ...\n",
      "18803   309626088  Age of Empires II HD Edition           6.7\n",
      "170024  309812026  Counter-Strike Nexon Zombies           0.0\n",
      "170025  309812026                     Robocraft           0.0\n",
      "10222   309824202                        Dota 2           0.7\n",
      "129085  309903146                        Dota 2           0.2\n",
      "\n",
      "[128804 rows x 3 columns]\n",
      "Empty DataFrame\n",
      "Columns: [UserID, Game, Hours_Played]\n",
      "Index: []\n",
      "数据集中包含了 12393 玩家，5155 游戏\n",
      "用户行为矩阵的稀疏性（填充比例）为0.20% \n"
     ]
    }
   ],
   "source": [
    "# stream 数据清洗\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "path = './steam-200k.csv'\n",
    "\n",
    "df = pd.read_csv(path, header = None, names = ['UserID', 'Game', 'Action', 'Hours', 'Not Needed'])\n",
    "\n",
    "# 数据探索\n",
    "\n",
    "print('显示前5条数据')\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "print('显示数据大小')\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "# 创建Hours_Played字段，替代原有的Action和Hours，0表示仅购买，大于0表示购买且游戏时长\n",
    "\n",
    "df['Hours_Played'] = df['Hours'].astype('float32')\n",
    "\n",
    "# 如果字段Action=purchase，并且Hours=1.0，将设置Hours_Played=0\n",
    "\n",
    "df.loc[(df['Action'] == 'purchase') & (df['Hours'] == 1.0), 'Hours_Played'] = 0\n",
    "\n",
    "print(df['Hours_Played'])\n",
    "\n",
    "print('增加了Hours_Played字段后，数据大小')\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "\n",
    "# 对数据从小到大进行排序, df下标也会发生变化\n",
    "\n",
    "df.UserID = df.UserID.astype('int')\n",
    "\n",
    "df = df.sort_values(['UserID', 'Game', 'Hours_Played'], ascending=True)\n",
    "\n",
    "\n",
    "\n",
    "# 删除重复项，并保留最后一项出现的项（因为最后一项是用户游戏时间，第一项为购买）\n",
    "\n",
    "clean_df = df.drop_duplicates(['UserID', 'Game'], keep = 'last')\n",
    "\n",
    "# 去掉不用的列：Action, Hours, Not Needed\n",
    "\n",
    "clean_df = clean_df.drop(['Action', 'Hours', 'Not Needed'], axis = 1)\n",
    "\n",
    "print('删除重复项后的数据集：')\n",
    "\n",
    "print(clean_df)\n",
    "\n",
    "print(clean_df.head(0))\n",
    "\n",
    "\n",
    "\n",
    "# 探索下数据集的特征\n",
    "\n",
    "n_users = len(clean_df.UserID.unique())\n",
    "\n",
    "n_games = len(clean_df.Game.unique())\n",
    "\n",
    "print('数据集中包含了 {0} 玩家，{1} 游戏'.format(n_users, n_games))\n",
    "\n",
    "\n",
    "\n",
    "# 矩阵的稀疏性\n",
    "\n",
    "sparsity = clean_df.shape[0] / float(n_users * n_games)\n",
    "\n",
    "print('用户行为矩阵的稀疏性（填充比例）为{:.2%} '.format(sparsity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
